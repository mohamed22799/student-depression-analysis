{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4fa905-8425-4ed9-801c-e78e460f7755",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #3b8d99; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    " Libraries\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33eb8a08-ddc7-4fcd-9e40-053fc9101ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: For loading, manipulating, and analyzing data in tabular form.\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib.pyplot: For creating static, interactive, and dynamic visualizations.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn: A statistical data visualization library built on top of matplotlib, offering easier and more visually appealing plots.\n",
    "import seaborn as sns\n",
    "\n",
    "# numpy : For numerical operations if needed for tasks like array computations or mathematical functions.\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea655f80-b0fd-4a3f-85af-3b37326b04da",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3b8d99; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    " Load dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc746a86-85d3-46a6-9f55-253371d6d83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Student</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Student</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BSc</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>Srinagar</td>\n",
       "      <td>Student</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BA</td>\n",
       "      <td>No</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Student</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BCA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Student</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>M.Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender  Age           City Profession  Academic Pressure  \\\n",
       "0   2    Male   33  Visakhapatnam    Student                  5   \n",
       "1   8  Female   24      Bangalore    Student                  2   \n",
       "2  26    Male   31       Srinagar    Student                  3   \n",
       "3  30  Female   28       Varanasi    Student                  3   \n",
       "4  32  Female   25         Jaipur    Student                  4   \n",
       "\n",
       "   Work Pressure  CGPA  Study Satisfaction  Job Satisfaction  \\\n",
       "0              0  8.97                   2                 0   \n",
       "1              0  5.90                   5                 0   \n",
       "2              0  7.03                   5                 0   \n",
       "3              0  5.59                   2                 0   \n",
       "4              0  8.13                   3                 0   \n",
       "\n",
       "      Sleep Duration Dietary Habits   Degree  \\\n",
       "0          5-6 hours        Healthy  B.Pharm   \n",
       "1          5-6 hours       Moderate      BSc   \n",
       "2  Less than 5 hours        Healthy       BA   \n",
       "3          7-8 hours       Moderate      BCA   \n",
       "4          5-6 hours       Moderate   M.Tech   \n",
       "\n",
       "  Have you ever had suicidal thoughts ?  Work/Study Hours  Financial Stress  \\\n",
       "0                                   Yes                 3               1.0   \n",
       "1                                    No                 3               2.0   \n",
       "2                                    No                 9               1.0   \n",
       "3                                   Yes                 4               5.0   \n",
       "4                                   Yes                 1               1.0   \n",
       "\n",
       "  Family History of Mental Illness  Depression  \n",
       "0                               No           1  \n",
       "1                              Yes           0  \n",
       "2                              Yes           0  \n",
       "3                              Yes           1  \n",
       "4                               No           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Student Depression Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34982f5-cad7-4f9b-96db-71be2020674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27901 entries, 0 to 27900\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   id                                     27901 non-null  int64  \n",
      " 1   Gender                                 27901 non-null  object \n",
      " 2   Age                                    27901 non-null  int64  \n",
      " 3   City                                   27901 non-null  object \n",
      " 4   Profession                             27901 non-null  object \n",
      " 5   Academic Pressure                      27901 non-null  int64  \n",
      " 6   Work Pressure                          27901 non-null  int64  \n",
      " 7   CGPA                                   27901 non-null  float64\n",
      " 8   Study Satisfaction                     27901 non-null  int64  \n",
      " 9   Job Satisfaction                       27901 non-null  int64  \n",
      " 10  Sleep Duration                         27901 non-null  object \n",
      " 11  Dietary Habits                         27901 non-null  object \n",
      " 12  Degree                                 27901 non-null  object \n",
      " 13  Have you ever had suicidal thoughts ?  27901 non-null  object \n",
      " 14  Work/Study Hours                       27901 non-null  int64  \n",
      " 15  Financial Stress                       27898 non-null  float64\n",
      " 16  Family History of Mental Illness       27901 non-null  object \n",
      " 17  Depression                             27901 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a164fb7-7cac-4256-b54d-7471b54a29e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27901, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af332429-4d27-4626-9974-df55517fc3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       0\n",
       "Gender                                   0\n",
       "Age                                      0\n",
       "City                                     0\n",
       "Profession                               0\n",
       "Academic Pressure                        0\n",
       "Work Pressure                            0\n",
       "CGPA                                     0\n",
       "Study Satisfaction                       0\n",
       "Job Satisfaction                         0\n",
       "Sleep Duration                           0\n",
       "Dietary Habits                           0\n",
       "Degree                                   0\n",
       "Have you ever had suicidal thoughts ?    0\n",
       "Work/Study Hours                         0\n",
       "Financial Stress                         3\n",
       "Family History of Mental Illness         0\n",
       "Depression                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236dcefa-e41a-4dee-b55c-fdacde6163c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fills the missing (NaN) values in the Financial Stress column\n",
    "df['Financial Stress']=df['Financial Stress'].fillna(df['Financial Stress'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27d9d3b-c4a3-4b37-8c93-4c8cbdb08a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove high cardinality columns\n",
    "df.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d81ae9f-8363-4c14-bcbd-6bf8852acdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f536da49-22b3-4bf5-b4b0-365fd2ad5133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Age', 'City', 'Profession', 'Academic Pressure',\n",
       "       'Work Pressure', 'CGPA', 'Study Satisfaction', 'Job Satisfaction',\n",
       "       'Sleep Duration', 'Dietary Habits', 'Degree',\n",
       "       'Have you ever had suicidal thoughts ?', 'Work/Study Hours',\n",
       "       'Financial Stress', 'Family History of Mental Illness', 'Depression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab385c26-4805-4d0b-bbdd-3bc916357b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      15547\n",
       "Female    12354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6be37e7d-3b24-4eab-b185-2c7d343a5116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27901.000000</td>\n",
       "      <td>27901.000000</td>\n",
       "      <td>27901.000000</td>\n",
       "      <td>27901.000000</td>\n",
       "      <td>27901.000000</td>\n",
       "      <td>27901.000000</td>\n",
       "      <td>27901.000000</td>\n",
       "      <td>27901.000000</td>\n",
       "      <td>27901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.822300</td>\n",
       "      <td>3.141214</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>7.656104</td>\n",
       "      <td>2.943837</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>7.156984</td>\n",
       "      <td>3.139867</td>\n",
       "      <td>0.585499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.905687</td>\n",
       "      <td>1.381465</td>\n",
       "      <td>0.043992</td>\n",
       "      <td>1.470707</td>\n",
       "      <td>1.361148</td>\n",
       "      <td>0.044394</td>\n",
       "      <td>3.707642</td>\n",
       "      <td>1.437269</td>\n",
       "      <td>0.492645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.290000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.770000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age  Academic Pressure  Work Pressure          CGPA  \\\n",
       "count  27901.000000       27901.000000   27901.000000  27901.000000   \n",
       "mean      25.822300           3.141214       0.000430      7.656104   \n",
       "std        4.905687           1.381465       0.043992      1.470707   \n",
       "min       18.000000           0.000000       0.000000      0.000000   \n",
       "25%       21.000000           2.000000       0.000000      6.290000   \n",
       "50%       25.000000           3.000000       0.000000      7.770000   \n",
       "75%       30.000000           4.000000       0.000000      8.920000   \n",
       "max       59.000000           5.000000       5.000000     10.000000   \n",
       "\n",
       "       Study Satisfaction  Job Satisfaction  Work/Study Hours  \\\n",
       "count        27901.000000      27901.000000      27901.000000   \n",
       "mean             2.943837          0.000681          7.156984   \n",
       "std              1.361148          0.044394          3.707642   \n",
       "min              0.000000          0.000000          0.000000   \n",
       "25%              2.000000          0.000000          4.000000   \n",
       "50%              3.000000          0.000000          8.000000   \n",
       "75%              4.000000          0.000000         10.000000   \n",
       "max              5.000000          4.000000         12.000000   \n",
       "\n",
       "       Financial Stress    Depression  \n",
       "count      27901.000000  27901.000000  \n",
       "mean           3.139867      0.585499  \n",
       "std            1.437269      0.492645  \n",
       "min            1.000000      0.000000  \n",
       "25%            2.000000      0.000000  \n",
       "50%            3.000000      1.000000  \n",
       "75%            4.000000      1.000000  \n",
       "max            5.000000      1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568f96b-a419-41f7-8bcb-e4985bd27a28",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3b8d99; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    " Data Preprocessing\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a671520f-110b-406f-8082-934b90188f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, AdaBoostRegressor,BaggingClassifier,BaggingRegressor,GradientBoostingClassifier,GradientBoostingRegressor,StackingClassifier,StackingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error,classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d2ace97-c562-4bd1-ac7a-1e0b737f2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Depression', axis=1)\n",
    "y=df['Depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59fcfcc9-564e-401f-894e-338a862629a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2025)\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2,random_state=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8671c71-41a3-4802-966b-11314e0d5fee",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3b8d99; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    " Model Selection\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54ffc65a-ad4e-4389-aa14-e0b985fb04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col=x_train.select_dtypes(['int','float']).columns\n",
    "categorical_col=x_train.select_dtypes(['object','category']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104e7d4-aaee-46ab-a9fe-49b087c18fce",
   "metadata": {},
   "source": [
    "## Scaling And Imputation\n",
    "\n",
    "\n",
    "- Scaling standardizes numerical features to ensure they are on the same scale.\n",
    "- Encoding transforms categorical variables into numerical format (via one-hot encoding).\n",
    "\n",
    "- Mean Imputation (Numerical): Suitable for continuous data like Financial Stress.\n",
    "- Mode Imputation (Categorical): Handles categorical columns effectively, as missing values are replaced with the most frequent category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d54864b-554c-458d-b60f-bdb09ac7286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Pipeline with Imputation and Scaling \n",
    "numerical_pipeline=Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='mean')), # Replace missing values with the mean # you can use median or mode\n",
    "    ('scar'le,StandardScaler()) # you can use Robust or MinMax \n",
    "])\n",
    "\n",
    "\n",
    "categorical_pipeline=Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler',OneHotEncoder(handle_unknown='ignore', drop='first')) # you can use LabelEncoder\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be5b47-878e-41fa-b306-ffb90a3530e3",
   "metadata": {},
   "source": [
    "## Combine into ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef695bae-4dfd-4412-8fa1-ef31e7bd4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_col) ,\n",
    "        ('cat', categorical_pipeline, categorical_col)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dde0f2-7c88-4ae9-8120-bac14f1b2a02",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #4CAF50; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    "  Logitic Regression\n",
    "</div>v>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68a8c822-7302-45bd-9f2c-c2ad38f584d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Logistic Regression Evaluation**\n",
      "r2_lr_train= 0.39755411069388613\n",
      "accuracy_lr_train = 0.8536626344086021\n",
      "f1_lr_train = 0.8766696559210837\n",
      "Train classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      7424\n",
      "           1       0.86      0.89      0.88     10432\n",
      "\n",
      "    accuracy                           0.85     17856\n",
      "   macro avg       0.85      0.85      0.85     17856\n",
      "weighted avg       0.85      0.85      0.85     17856\n",
      "\n",
      "r2_lr_val= 0.3599108909245067\n",
      "accuracy_lr_val = 0.8454301075268817\n",
      "f1_lr_val = 0.8718900854066097\n",
      "Validation classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.81      1820\n",
      "           1       0.86      0.89      0.87      2644\n",
      "\n",
      "    accuracy                           0.85      4464\n",
      "   macro avg       0.84      0.84      0.84      4464\n",
      "weighted avg       0.84      0.85      0.84      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with preprocessing and Logistic Regression\n",
    "lr_pipeline=Pipeline(steps=[\n",
    "    ('preprocessing',preprocessor),\n",
    "    ('modeling',LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "lr_pipeline.fit(x_train,y_train)\n",
    "train_predictions=lr_pipeline.predict(x_train)\n",
    "val_predictions=lr_pipeline.predict(x_val)\n",
    "\n",
    "print('**Logistic Regression Evaluation**')\n",
    "\n",
    "r2_lr_train= r2_score(y_train,train_predictions)\n",
    "accuracy_lr_train = accuracy_score(y_train, train_predictions)\n",
    "f1_lr_train = f1_score(y_train, train_predictions)\n",
    "\n",
    "print('r2_lr_train=', r2_lr_train )\n",
    "print('accuracy_lr_train =', accuracy_lr_train )\n",
    "print('f1_lr_train =', f1_lr_train )\n",
    "print('Train classification report\\n',classification_report(y_train,train_predictions))\n",
    "\n",
    "r2_lr_val= r2_score(y_val,val_predictions)\n",
    "accuracy_lr_val = accuracy_score(y_val, val_predictions)\n",
    "f1_lr_val = f1_score(y_val, val_predictions)\n",
    "\n",
    "print('r2_lr_val=', r2_lr_val)\n",
    "print('accuracy_lr_val =', accuracy_lr_val)\n",
    "print('f1_lr_val =', f1_lr_val)\n",
    "print('Validation classification report\\n',classification_report(y_val,val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a49b6b-9027-401f-850c-7f673a96fd71",
   "metadata": {},
   "source": [
    "## Logistic Regression Interpretation\n",
    "\n",
    "- The logistic regression model demonstrates a good balance between precision and recall, with an overall accuracy of around **85%** on both training and validation datasets. The R² score indicates that there may be room for improvement in capturing the variance in the data.\r\n",
    "- \r\n",
    "If we change the `test_size` parameter to **0.3**, it may lead to an increase in the R² score, potentially approaching **0.4**. However, it's important to note that increasing the test size can affect the training data available for the model, which might influence both the R² score and the classification metrics. Overall, the classification metrics indicate that the model performs well in distinguishing between the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582fd51-7994-4bcf-9622-79078a62c519",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #4CAF50; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    "  KNN\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75606420-2d7e-497d-881a-7bbc63616e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**KNN Evaluation**\n",
      "r2_knn_train= 0.4711018484239474\n",
      "accuracy_knn_train = 0.8715277777777778\n",
      "f1_knn_train = 0.8931532370749884\n",
      "Train classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      7424\n",
      "           1       0.87      0.92      0.89     10432\n",
      "\n",
      "    accuracy                           0.87     17856\n",
      "   macro avg       0.87      0.86      0.87     17856\n",
      "weighted avg       0.87      0.87      0.87     17856\n",
      "\n",
      "r2_knn_val= 0.1994247809678974\n",
      "accuracy_knn_val = 0.8066756272401434\n",
      "f1_knn_val = 0.8422014993600293\n",
      "Validation classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75      1820\n",
      "           1       0.82      0.87      0.84      2644\n",
      "\n",
      "    accuracy                           0.81      4464\n",
      "   macro avg       0.80      0.79      0.80      4464\n",
      "weighted avg       0.81      0.81      0.80      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_pipeline=Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('modeling', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(x_train,y_train)\n",
    "train_predictions=knn_pipeline.predict(x_train)\n",
    "val_predictions=knn_pipeline.predict(x_val)\n",
    "\n",
    "print('**KNN Evaluation**')\n",
    "\n",
    "r2_knn_train= r2_score(y_train,train_predictions)\n",
    "accuracy_knn_train = accuracy_score(y_train, train_predictions)\n",
    "f1_knn_train = f1_score(y_train, train_predictions)\n",
    "\n",
    "print('r2_knn_train=', r2_knn_train )\n",
    "print('accuracy_knn_train =', accuracy_knn_train )\n",
    "print('f1_knn_train =', f1_knn_train )\n",
    "print('Train classification report\\n',classification_report(y_train,train_predictions))\n",
    "\n",
    "r2_knn_val= r2_score(y_val,val_predictions)\n",
    "accuracy_knn_val = accuracy_score(y_val, val_predictions)\n",
    "f1_knn_val = f1_score(y_val, val_predictions)\n",
    "\n",
    "print('r2_knn_val=', r2_knn_val)\n",
    "print('accuracy_knn_val =', accuracy_knn_val)\n",
    "print('f1_knn_val =', f1_knn_val)\n",
    "print('Validation classification report\\n',classification_report(y_val,val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8dd461-d75b-46ae-a24b-11bb9734300b",
   "metadata": {},
   "source": [
    "## KNN Interpretation\r\n",
    "\r\n",
    "### Fitting Condition\r\n",
    "The KNN model demonstrates a reasonable fit with a **R² Score** of **0.4711** on the training set. This indicates that approximately **47.11%** of the variance in the dependent variable can be explained by the independent variables. There may be room for improvement in capturing the variance in the datScore\r\n",
    "The R² score on the validation set is also **0.4711**, suggesting consistency in performance. This score indicates that the model may not fully capture the underlying patterns in the data.\r\n",
    "\r\n",
    "### Improving Results\r\n",
    "To improve the model's performance, consider the following strategies:\r\n",
    "- **Hyperparameter Tuning**: Experiment with different values for the number of neighbors (k) and distance metrics.\r\n",
    "- **Feature Scaling**: Normalize or standardize the feature set to improve distance calnformation.\r\n",
    "\r\n",
    "Overall, the classification metrics indicate that the model performs reasonably well in distinguishing between the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7c21e-8630-45d1-a0af-fd8e14111794",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e53cdff-97c0-464f-8ac2-9088dc71fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'modeling__metric': 'manhattan', 'modeling__n_neighbors': 11}\n",
      "best cross-validation: 0.8313729047261708\n",
      "**KNN Evaluation**\n",
      "r2_t_knn_train= 0.4106958694732388\n",
      "accuracy_t_knn_train = 0.8568548387096774\n",
      "f1_t_knn_train = 0.8823637702503682\n",
      "Train classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82      7424\n",
      "           1       0.85      0.92      0.88     10432\n",
      "\n",
      "    accuracy                           0.86     17856\n",
      "   macro avg       0.86      0.84      0.85     17856\n",
      "weighted avg       0.86      0.86      0.86     17856\n",
      "\n",
      "r2_t_knn_val= 0.2587953649980881\n",
      "accuracy_t_knn_val = 0.8210125448028673\n",
      "f1_t_knn_val = 0.855854230561068\n",
      "Validation classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.76      1820\n",
      "           1       0.82      0.90      0.86      2644\n",
      "\n",
      "    accuracy                           0.82      4464\n",
      "   macro avg       0.82      0.80      0.81      4464\n",
      "weighted avg       0.82      0.82      0.82      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_pipeline=Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('modeling', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'modeling__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'modeling__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search=GridSearchCV(knn_pipeline, param_grid, cv=5, n_jobs=-1) \n",
    "            # cv=5, this specifies the number of cross-validation folds. In this case, the dataset will be split into 5 subsets (folds). The model will be trained on 4 of these folds and validated on the remaining fold. This process will be repeated 5 times, each time with a different fold used for validation.\n",
    "            # n_jobs=-1, This parameter allows the grid search to use all available CPU cores for computation. Setting n_jobs to -1 speeds up the process by parallelizing the execution of the cross-validation folds, which is especially beneficial when working with large datasets.\n",
    "\n",
    "grid_search.fit(x_train,y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "print('best parameters:', grid_search.best_params_)\n",
    "print('best cross-validation:', grid_search.best_score_)\n",
    "#print('best estimator:', grid_search.best_estimator_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_knn_model=grid_search.best_estimator_\n",
    "train_predictions=best_knn_model.predict(x_train)\n",
    "val_predictions=best_knn_model.predict(x_val)\n",
    "\n",
    "\n",
    "# Print classification reports for training and validation sets\n",
    "print('**KNN Evaluation**')\n",
    "\n",
    "r2_t_knn_train= r2_score(y_train,train_predictions)\n",
    "accuracy_t_knn_train = accuracy_score(y_train, train_predictions)\n",
    "f1_t_knn_train = f1_score(y_train, train_predictions)\n",
    "\n",
    "print('r2_t_knn_train=', r2_t_knn_train )\n",
    "print('accuracy_t_knn_train =', accuracy_t_knn_train )\n",
    "print('f1_t_knn_train =', f1_t_knn_train )\n",
    "print('Train classification report\\n',classification_report(y_train,train_predictions))\n",
    "\n",
    "r2_t_knn_val= r2_score(y_val,val_predictions)\n",
    "accuracy_t_knn_val = accuracy_score(y_val, val_predictions)\n",
    "f1_t_knn_val = f1_score(y_val, val_predictions)\n",
    "\n",
    "print('r2_t_knn_val=', r2_t_knn_val)\n",
    "print('accuracy_t_knn_val =', accuracy_t_knn_val)\n",
    "print('f1_t_knn_val =', f1_t_knn_val)\n",
    "print('Validation classification report\\n',classification_report(y_val,val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68257e-790d-4ac1-bff3-f0afe8b8db8a",
   "metadata": {},
   "source": [
    "## **KNN Interpretation After Tuning**\r\n",
    "\r\n",
    "#### **Fitting Condition:**\r\n",
    "- The KNN model shows a slightly reduced fit after tuning, with an R² Score of **0.4107** on the training set, explaining approximately **41.07%** of the variance. This suggests that the tuning parameters resulted in a slight decrease in variance capture.\r\n",
    "\r\n",
    "#### **R² Score:**\r\n",
    "- The validation R² Score is also **0.4107**, indicating consistency but highlighting a slight drop in the model's ability to generalize compared to the pre-tuning phase.\r\n",
    "\r\n",
    "#### **Hyperparameter Tuning Outcome:**\r\n",
    "- The hyperparameter tuning did not yield a significant improvement in performance. This suggests that KNN may not be the most suitable model for this dataset.\r\n",
    "\r\n",
    "#### **Next Steps:**\r\n",
    "- Consider trying another model, such as Decision Trees, Ensemble Methods, or Boosting techniques, to explore better performance and generalization.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d0b86-5722-40a2-af2d-e22c4cd1e246",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #4CAF50; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\r\n",
    "  Decision Tree\r\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b04e99a6-77e5-4eb6-a2ef-f0f9b77ba936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*DT Evaluation*\n",
      "r2_dt_train= 1.0\n",
      "accuracy_dt_train = 1.0\n",
      "f1_dt_train = 1.0\n",
      "Train classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7424\n",
      "           1       1.00      1.00      1.00     10432\n",
      "\n",
      "    accuracy                           1.00     17856\n",
      "   macro avg       1.00      1.00      1.00     17856\n",
      "weighted avg       1.00      1.00      1.00     17856\n",
      "\n",
      "r2_dt_val= 0.035228009509401303\n",
      "accuracy_dt_val = 0.7670250896057348\n",
      "f1_dt_val = 0.8036253776435045\n",
      "Validation classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71      1820\n",
      "           1       0.80      0.80      0.80      2644\n",
      "\n",
      "    accuracy                           0.77      4464\n",
      "   macro avg       0.76      0.76      0.76      4464\n",
      "weighted avg       0.77      0.77      0.77      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT_pipeline=Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('modeling', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "DT_pipeline.fit(x_train,y_train)\n",
    "train_predictions=DT_pipeline.predict(x_train)\n",
    "val_predictions=DT_pipeline.predict(x_val)\n",
    "\n",
    "print('*DT Evaluation*')\n",
    "\n",
    "r2_dt_train= r2_score(y_train,train_predictions)\n",
    "accuracy_dt_train = accuracy_score(y_train, train_predictions)\n",
    "f1_dt_train = f1_score(y_train, train_predictions)\n",
    "\n",
    "print('r2_dt_train=', r2_dt_train )\n",
    "print('accuracy_dt_train =', accuracy_dt_train )\n",
    "print('f1_dt_train =', f1_dt_train )\n",
    "print('Train classification report\\n',classification_report(y_train,train_predictions))\n",
    "\n",
    "r2_dt_val= r2_score(y_val,val_predictions)\n",
    "accuracy_dt_val = accuracy_score(y_val, val_predictions)\n",
    "f1_dt_val = f1_score(y_val, val_predictions)\n",
    "\n",
    "print('r2_dt_val=', r2_dt_val)\n",
    "print('accuracy_dt_val =', accuracy_dt_val)\n",
    "print('f1_dt_val =', f1_dt_val)\n",
    "print('Validation classification report\\n',classification_report(y_val,val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4cf561-a45c-494d-b91d-fe12f7c79fc4",
   "metadata": {},
   "source": [
    "## Interpretation\r\n",
    "\r\n",
    "### Fitting Condition\r\n",
    "The Decision Tree Classifier exhibits a **perfect fit** on the training set with an **R² Score** of **1.0**, explaining **100%** of the variance. However, the **R² Score** on the validation set is only **0.0380**, indicating that the model is **overfitting**. This suggests that while the model captures the training data perfectly, it fails to generalize to unseen data.\r\n",
    "\r\n",
    "### Classification Report\r\n",
    "- **Training Set**: Precision, Recall, and F1-Score are all **1.00** for both classes, reflecting perfect classification.\r\n",
    "- **Validation Set**: Precision i1 **0.76** for class 0 an0 **0.88** for class 1, with Recall a1 **0.77** an0 **0.81** respectively, showing some missed cases.\r\n",
    "\r\n",
    "### Improving Results\r\n",
    "To enhance the model's performance and address overfitting, consider the following strategies:\r\n",
    "- **Hyperparameter Tuning**: Adjust parameters such as `max_depth` and `min_samples_split` to find a better balance between bias and ce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26fddf-8c51-439b-8af4-b88fda5f5903",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf65071d-eee8-412b-a8ce-eedc86600643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'modeling__max_depth': 5, 'modeling__min_samples_leaf': 1, 'modeling__min_samples_split': 2}\n",
      "Best cross-validation score: 0.8278452182458983\n",
      "*DT Evaluation*\n",
      "r2_t_dt_train= 0.31409241458641834\n",
      "accuracy_t_dt_train = 0.8333893369175627\n",
      "f1_t_dt_train = 0.8621983417481125\n",
      "Train classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      7424\n",
      "           1       0.83      0.89      0.86     10432\n",
      "\n",
      "    accuracy                           0.83     17856\n",
      "   macro avg       0.83      0.82      0.83     17856\n",
      "weighted avg       0.83      0.83      0.83     17856\n",
      "\n",
      "r2_t_dt_val= 0.2587953649980881\n",
      "accuracy_t_dt_val = 0.8210125448028673\n",
      "f1_t_dt_val = 0.8541704690636978\n",
      "Validation classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1820\n",
      "           1       0.83      0.89      0.85      2644\n",
      "\n",
      "    accuracy                           0.82      4464\n",
      "   macro avg       0.82      0.81      0.81      4464\n",
      "weighted avg       0.82      0.82      0.82      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor), \n",
    "    ('modeling', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid \n",
    "param_grid = {\n",
    "    'modeling__max_depth': [None, 5, 10, 15],\n",
    "    'modeling__min_samples_split': [2, 5, 10],\n",
    "    'modeling__min_samples_leaf': [1, 2, 4]  \n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(DT_pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "print('Best cross-validation score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model \n",
    "best_DT_model = grid_search.best_estimator_\n",
    "train_predictions = best_DT_model.predict(x_train)\n",
    "val_predictions = best_DT_model.predict(x_val) \n",
    "\n",
    "print('*DT Evaluation*')\n",
    "\n",
    "r2_t_dt_train= r2_score(y_train,train_predictions)\n",
    "accuracy_t_dt_train = accuracy_score(y_train, train_predictions)\n",
    "f1_t_dt_train = f1_score(y_train, train_predictions)\n",
    "\n",
    "print('r2_t_dt_train=', r2_t_dt_train )\n",
    "print('accuracy_t_dt_train =', accuracy_t_dt_train )\n",
    "print('f1_t_dt_train =', f1_t_dt_train )\n",
    "print('Train classification report\\n',classification_report(y_train,train_predictions))\n",
    "\n",
    "r2_t_dt_val= r2_score(y_val,val_predictions)\n",
    "accuracy_t_dt_val = accuracy_score(y_val, val_predictions)\n",
    "f1_t_dt_val = f1_score(y_val, val_predictions)\n",
    "\n",
    "print('r2_t_dt_val=', r2_t_dt_val)\n",
    "print('accuracy_t_dt_val =', accuracy_t_dt_val)\n",
    "print('f1_t_dt_val =', f1_t_dt_val)\n",
    "print('Validation classification report\\n',classification_report(y_val,val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f7c60-6a9c-4e06-9eb9-b653354393e4",
   "metadata": {},
   "source": [
    "## Interpretation After Tunning\n",
    "\n",
    "1. **Model Fit Analysis:**\n",
    "   - The R² score of 0.31 indicates that the model explains only 31% of the variance in the training data. While the accuracy is relatively high (83%), the gap between precision and recall suggests potential issues with class balance or model complexity.\n",
    "   - Given that the model performs well on the training set, it may be overfitting, especially if performance on the validation set is significantly lower.\n",
    "\n",
    "2. **Good Fit vs. Overfit:**\n",
    "   - The model appears to be a good fit for the training data, but further evaluation on the validation set is necessary to confirm if it generalizes well. If performance drops on the validation set, it could indicate overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a0e4d-064a-4b47-8a56-f26d8a8fda86",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #4CAF50; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    "  Ensemble Techniques (Random Forest)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82884cd6-4bf1-4edc-b9a7-b902f93200bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Random Forest Evaluation*\n",
      "r2_rf_train= 1.0\n",
      "accuracy_rf_train = 1.0\n",
      "f1_rf_train = 1.0\n",
      "Train classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7424\n",
      "           1       1.00      1.00      1.00     10432\n",
      "\n",
      "    accuracy                           1.00     17856\n",
      "   macro avg       1.00      1.00      1.00     17856\n",
      "weighted avg       1.00      1.00      1.00     17856\n",
      "\n",
      "r2_rf_val= 0.3190936144037505\n",
      "accuracy_rf_val = 0.8355734767025089\n",
      "f1_rf_val = 0.8644756277695717\n",
      "Validation classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      1820\n",
      "           1       0.84      0.89      0.86      2644\n",
      "\n",
      "    accuracy                           0.84      4464\n",
      "   macro avg       0.83      0.82      0.83      4464\n",
      "weighted avg       0.83      0.84      0.83      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Random_forest_pipeline=Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('modeling', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "Random_forest_pipeline.fit(x_train,y_train)\n",
    "train_predictions=Random_forest_pipeline.predict(x_train)\n",
    "val_predictions=Random_forest_pipeline.predict(x_val)\n",
    "\n",
    "print('*Random Forest Evaluation*')\n",
    "\n",
    "r2_rf_train= r2_score(y_train,train_predictions)\n",
    "accuracy_rf_train = accuracy_score(y_train, train_predictions)\n",
    "f1_rf_train = f1_score(y_train, train_predictions)\n",
    "\n",
    "print('r2_rf_train=', r2_rf_train )\n",
    "print('accuracy_rf_train =', accuracy_rf_train )\n",
    "print('f1_rf_train =', f1_rf_train )\n",
    "print('Train classification report\\n',classification_report(y_train,train_predictions))\n",
    "\n",
    "r2_rf_val= r2_score(y_val,val_predictions)\n",
    "accuracy_rf_val = accuracy_score(y_val, val_predictions)\n",
    "f1_rf_val = f1_score(y_val, val_predictions)\n",
    "\n",
    "print('r2_rf_val=', r2_rf_val)\n",
    "print('accuracy_rf_val =', accuracy_rf_val)\n",
    "print('f1_rf_val =', f1_rf_val)\n",
    "print('Validation classification report\\n',classification_report(y_val,val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e217cc4-3ead-428d-ae96-5060fa419fcb",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "### Fit Analysis\n",
    "- **Training Results**: The model performs perfectly on the training set, indicated by an R² score of 1.0 and perfect classification metrics. This often suggests that the model may be **overfitting** to the training data.\n",
    "- **Validation Results**: The significantly lower R² score (0.3265) on the validation set, along with the precision, recall, and F1-score values, indicates that the model does not generalize well to unseen data. This reinforces the possibility of **overfitting**.\n",
    "\n",
    "## Recommendations for Improvement\n",
    "1. **Hyperparameter Tuning**: Experiment with different hyperparameter settings using techniques like grid search or random search.\n",
    "2. **Ensemble Methods**: Consider using ensemble methods like bagging or boosting to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f138f8-8989-4d70-b900-de7746af0e5c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #4CAF50; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    "  Ensemble Techniques (Bagging)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "87e50670-ac99-4157-8fb8-3607f4231289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Bagging Classifier Evaluation*\n",
      "r2_rf_train= 0.9481246363972922\n",
      "accuracy_rf_train = 0.9873991935483871\n",
      "f1_rf_train = 0.9891769685891577\n",
      "Train classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      7424\n",
      "           1       0.99      0.99      0.99     10432\n",
      "\n",
      "    accuracy                           0.99     17856\n",
      "   macro avg       0.99      0.99      0.99     17856\n",
      "weighted avg       0.99      0.99      0.99     17856\n",
      "\n",
      "r2_rf_val= 0.25508470349620116\n",
      "accuracy_rf_val = 0.8201164874551972\n",
      "f1_rf_val = 0.8488612836438924\n",
      "Validation classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78      1820\n",
      "           1       0.84      0.85      0.85      2644\n",
      "\n",
      "    accuracy                           0.82      4464\n",
      "   macro avg       0.81      0.81      0.81      4464\n",
      "weighted avg       0.82      0.82      0.82      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('modeling', BaggingClassifier())  \n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "bagging_pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = bagging_pipeline.predict(x_train)\n",
    "val_predictions = bagging_pipeline.predict(x_val)\n",
    "\n",
    "# Evaluation\n",
    "print('*Bagging Classifier Evaluation*')\n",
    "\n",
    "r2_bagging_train= r2_score(y_train,train_predictions)\n",
    "accuracy_bagging_train = accuracy_score(y_train, train_predictions)\n",
    "f1_bagging_train = f1_score(y_train, train_predictions)\n",
    "\n",
    "print('r2_rf_train=', r2_bagging_train )\n",
    "print('accuracy_rf_train =', accuracy_bagging_train )\n",
    "print('f1_rf_train =', f1_bagging_train )\n",
    "print('Train classification report\\n',classification_report(y_train,train_predictions))\n",
    "\n",
    "r2_bagging_val= r2_score(y_val,val_predictions)\n",
    "accuracy_bagging_val = accuracy_score(y_val, val_predictions)\n",
    "f1_bagging_val = f1_score(y_val, val_predictions)\n",
    "\n",
    "print('r2_rf_val=', r2_bagging_val)\n",
    "print('accuracy_rf_val =', accuracy_bagging_val)\n",
    "print('f1_rf_val =', f1_bagging_val)\n",
    "print('Validation classification report\\n',classification_report(y_val,val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181283c-1adb-43bf-903a-3865f3a1f783",
   "metadata": {},
   "source": [
    "## Interpretation \n",
    "- **Fit Status**: The model shows signs of **overfitting**, as it performs very well on the training data but has lower performance metrics on the validation set.\n",
    "\n",
    "### Recommendations for Improvement\n",
    "1. **Hyperparameter Tuning**: Experiment with parameters such as `n_estimators` or `max_samples`.\n",
    "2. **Increase Data**: Incorporate more diverse training data if possible.\n",
    "3. **Ensemble Techniques**: Combine with other methods (e.g., Random Forest) to enhance robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f05c2c-c1fc-4191-bdef-f4338d8dfa07",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3b8d99; color: white; padding: 20px; border-radius: 5px; font-size: 30px; text-align: center; width: fit-content; margin: 0 auto;\">\n",
    " Comparing The models\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "41ee737e-7998-4f8f-a799-c459a33c8c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>R² Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Train)</td>\n",
       "      <td>0.853663</td>\n",
       "      <td>0.876670</td>\n",
       "      <td>0.397554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression (val)</td>\n",
       "      <td>0.845430</td>\n",
       "      <td>0.871890</td>\n",
       "      <td>0.359911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree (Train)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree (val)</td>\n",
       "      <td>0.767025</td>\n",
       "      <td>0.803625</td>\n",
       "      <td>0.035228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned DT (train)</td>\n",
       "      <td>0.833389</td>\n",
       "      <td>0.862198</td>\n",
       "      <td>0.314092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned DT (val)</td>\n",
       "      <td>0.821013</td>\n",
       "      <td>0.854170</td>\n",
       "      <td>0.258795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN (Train)</td>\n",
       "      <td>0.871528</td>\n",
       "      <td>0.893153</td>\n",
       "      <td>0.471102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN (val)</td>\n",
       "      <td>0.806676</td>\n",
       "      <td>0.842201</td>\n",
       "      <td>0.199425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuned KNN (Train)</td>\n",
       "      <td>0.856855</td>\n",
       "      <td>0.882364</td>\n",
       "      <td>0.410696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned KNN (val)</td>\n",
       "      <td>0.821013</td>\n",
       "      <td>0.855854</td>\n",
       "      <td>0.258795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest (Train)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest (val)</td>\n",
       "      <td>0.835573</td>\n",
       "      <td>0.864476</td>\n",
       "      <td>0.319094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging (Train)</td>\n",
       "      <td>0.987399</td>\n",
       "      <td>0.989177</td>\n",
       "      <td>0.948125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bagging (val)</td>\n",
       "      <td>0.820116</td>\n",
       "      <td>0.848861</td>\n",
       "      <td>0.255085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Accuracy  F1 Score  R² Score\n",
       "0   Logistic Regression (Train)  0.853663  0.876670  0.397554\n",
       "1     Logistic Regression (val)  0.845430  0.871890  0.359911\n",
       "2         Decision Tree (Train)  1.000000  1.000000  1.000000\n",
       "3           Decision Tree (val)  0.767025  0.803625  0.035228\n",
       "4              Tuned DT (train)  0.833389  0.862198  0.314092\n",
       "5                Tuned DT (val)  0.821013  0.854170  0.258795\n",
       "6                   KNN (Train)  0.871528  0.893153  0.471102\n",
       "7                     KNN (val)  0.806676  0.842201  0.199425\n",
       "8             Tuned KNN (Train)  0.856855  0.882364  0.410696\n",
       "9               Tuned KNN (val)  0.821013  0.855854  0.258795\n",
       "10        Random Forest (Train)  1.000000  1.000000  1.000000\n",
       "11          Random Forest (val)  0.835573  0.864476  0.319094\n",
       "12              Bagging (Train)  0.987399  0.989177  0.948125\n",
       "13                Bagging (val)  0.820116  0.848861  0.255085"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your results data as a dictionary\n",
    "results = {\n",
    "    'Model': ['Logistic Regression (Train)', 'Logistic Regression (val)', \n",
    "              'Decision Tree (Train)', 'Decision Tree (val)', \n",
    "              'Tuned DT (train)', 'Tuned DT (val)',\n",
    "              'KNN (Train)', 'KNN (val)', \n",
    "              'Tuned KNN (Train)', 'Tuned KNN (val)', \n",
    "              'Random Forest (Train)', 'Random Forest (val)',  \n",
    "              'Bagging (Train)', 'Bagging (val)'],\n",
    "    'Accuracy': [accuracy_lr_train, accuracy_lr_val, \n",
    "                 accuracy_dt_train, accuracy_dt_val, \n",
    "                 accuracy_t_dt_train, accuracy_t_dt_val, \n",
    "                 accuracy_knn_train, accuracy_knn_val, \n",
    "                 accuracy_t_knn_train, accuracy_t_knn_val, \n",
    "                 accuracy_rf_train, accuracy_rf_val, \n",
    "                 accuracy_bagging_train, accuracy_bagging_val],\n",
    "    'F1 Score': [f1_lr_train, f1_lr_val, \n",
    "                 f1_dt_train, f1_dt_val, \n",
    "                 f1_t_dt_train, f1_t_dt_val, \n",
    "                 f1_knn_train, f1_knn_val, \n",
    "                 f1_t_knn_train, f1_t_knn_val, \n",
    "                 f1_rf_train, f1_rf_val, \n",
    "                 f1_bagging_train, f1_bagging_val],\n",
    "    'R² Score': [r2_lr_train, r2_lr_val, \n",
    "                 r2_dt_train, r2_dt_val, \n",
    "                 r2_t_dt_train, r2_t_dt_val, \n",
    "                 r2_knn_train, r2_knn_val, \n",
    "                 r2_t_knn_train, r2_t_knn_val, \n",
    "                 r2_rf_train, r2_rf_val, \n",
    "                 r2_bagging_train, r2_bagging_val]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the results dictionary\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)  # Set float format for better readability\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205eaa6-24f5-4bfe-bf9b-5e697edd854a",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "\n",
    "- The best model is: **Logistic Regression** as it appears to be the best fit as it maintains a good balance between training and validation metrics.\n",
    "- Also, **KNN** performs well without overfitting so, it's also a good choice\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc7b6c-8423-4719-b940-870a1a5c5aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
